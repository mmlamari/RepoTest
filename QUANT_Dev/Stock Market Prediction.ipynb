{
 "metadata": {
  "name": "",
  "signature": "sha256:8121104944db48286d9b1ac28898adff3bec00557831c0a4c968ce0aa4a49949"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import datetime\n",
      "from sklearn import preprocessing\n",
      "#from datetime import datetime\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import neighbors\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.svm import SVC\n",
      "import operator\n",
      "import pandas.io.data\n",
      "from sklearn.qda import QDA\n",
      "import re\n",
      "from dateutil import parser\n",
      "\n",
      "#from backtest import Strategy, Portfolio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def addFeatures(dataframe, adjclose, returns, n):\n",
      "    \"\"\"\n",
      "    operates on two columns of dataframe:\n",
      "    - n >= 2\n",
      "    - given Return_* computes the return of day i respect to day i-n. \n",
      "    - given AdjClose_* computes its moving average on n days\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    return_n = adjclose[9:] + \"Time\" + str(n)\n",
      "    dataframe[return_n] = dataframe[adjclose].pct_change(n)\n",
      "    \n",
      "    roll_n = returns[7:] + \"RolMean\" + str(n)\n",
      "    dataframe[roll_n] = pd.rolling_mean(dataframe[returns], n)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def applyRollMeanDelayedReturns(datasets, delta):\n",
      "    \"\"\"\n",
      "    applies rolling mean and delayed returns to each dataframe in the list\n",
      "    \"\"\"\n",
      "    for dataset in datasets:\n",
      "        columns = dataset.columns    \n",
      "        adjclose = columns[-2]\n",
      "        returns = columns[-1]\n",
      "        for n in delta:\n",
      "            addFeatures(dataset, adjclose, returns, n)\n",
      "    \n",
      "    return datasets    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mergeDataframes(datasets, index, cut):\n",
      "    \"\"\"\n",
      "    merges datasets in the list \n",
      "    \"\"\"\n",
      "    subset = []\n",
      "    subset = [dataset.iloc[:, index:] for dataset in datasets[1:]]\n",
      "    \n",
      "    first = subset[0].join(subset[1:], how = 'outer')\n",
      "    finance = datasets[0].iloc[:, index:].join(first, how = 'left') \n",
      "    finance = finance[finance.index > cut]\n",
      "    return finance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def applyTimeLag(dataset, lags, delta):\n",
      "    \"\"\"\n",
      "    apply time lag to return columns selected according  to delta.\n",
      "    Days to lag are contained in the lads list passed as argument.\n",
      "    Returns a NaN free dataset obtained cutting the lagged dataset\n",
      "    at head and tail\n",
      "    \"\"\"\n",
      "    \n",
      "    dataset.Return_Out = dataset.Return_Out.shift(-1)\n",
      "    maxLag = max(lags)\n",
      " \n",
      "    columns = dataset.columns[::(2*max(delta)-1)]\n",
      "    for column in columns:\n",
      "        for lag in lags:\n",
      "            newcolumn = column + str(lag)\n",
      "            dataset[newcolumn] = dataset[column].shift(lag)\n",
      " \n",
      "    return dataset.iloc[maxLag:-1,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getStock(symbol, start, end):\n",
      "    \"\"\"\n",
      "    Downloads Stock from Yahoo Finance.\n",
      "    Computes daily Returns based on Adj Close.\n",
      "    Returns pandas dataframe.\n",
      "    \"\"\"\n",
      "    df =  pd.io.data.get_data_yahoo(symbol, start, end)\n",
      " \n",
      "    df.columns.values[-1] = 'AdjClose'\n",
      "    df.columns = df.columns + '_' + symbol\n",
      "    df['Return_%s' %symbol] = df['AdjClose_%s' %symbol].pct_change()\n",
      "    \n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def getStockFromQuandl(symbol, name, start, end):\n",
      "    \"\"\"\n",
      "    Downloads Stock from Quandl.\n",
      "    Computes daily Returns based on Adj Close.\n",
      "    Returns pandas dataframe.\n",
      "    \"\"\"\n",
      "    import Quandl\n",
      "    df =  Quandl.get(symbol, trim_start = start, trim_end = end, authtoken=\"your token\")\n",
      " \n",
      "    df.columns.values[-1] = 'AdjClose'\n",
      "    df.columns = df.columns + '_' + name\n",
      "    df['Return_%s' %name] = df['AdjClose_%s' %name].pct_change()\n",
      "    \n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def getStockDataFromWeb(fout, start_string, end_string):\n",
      "    \"\"\"\n",
      "    Collects predictors data from Yahoo Finance and Quandl.\n",
      "    Returns a list of dataframes.\n",
      "    \"\"\"\n",
      "    start = parser.parse(start_string)\n",
      "    end = parser.parse(end_string)\n",
      "    \n",
      "    nasdaq = getStock('^IXIC', start, end)\n",
      "    frankfurt = getStock('^GDAXI', start, end)\n",
      "    london = getStock('^FTSE', start, end)\n",
      "    paris = getStock('^FCHI', start, end)\n",
      "    hkong = getStock('^HSI', start, end)\n",
      "    nikkei = getStock('^N225', start, end)\n",
      "    australia = getStock('^AXJO', start, end)\n",
      "    \n",
      "    djia = getStockFromQuandl(\"YAHOO/INDEX_DJI\", 'Djia', start_string, end_string) \n",
      "    \n",
      "    out =  pd.io.data.get_data_yahoo(fout, start, end)\n",
      "    out.columns.values[-1] = 'AdjClose'\n",
      "    out.columns = out.columns + '_Out'\n",
      "    out['Return_Out'] = out['AdjClose_Out'].pct_change()\n",
      "    \n",
      "    return [out, nasdaq, djia, frankfurt, london, paris, hkong, nikkei, australia]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prepareDataForClassification(dataset, start_test):\n",
      "    \"\"\"\n",
      "    generates categorical output column, attach to dataframe \n",
      "    label the categories and split into train and test\n",
      "    \"\"\"\n",
      "    le = preprocessing.LabelEncoder()\n",
      "    \n",
      "    dataset['UpDown'] = dataset['Return_Out']\n",
      "    dataset.UpDown[dataset.UpDown >= 0] = 'Up'\n",
      "    dataset.UpDown[dataset.UpDown < 0] = 'Down'\n",
      "    dataset.UpDown = le.fit(dataset.UpDown).transform(dataset.UpDown)\n",
      "    \n",
      "    features = dataset.columns[1:-1]\n",
      "    X = dataset[features]    \n",
      "    y = dataset.UpDown    \n",
      "    \n",
      "    X_train = X[X.index < start_test]\n",
      "    y_train = y[y.index < start_test]              \n",
      "    \n",
      "    X_test = X[X.index >= start_test]    \n",
      "    y_test = y[y.index >= start_test]\n",
      "    \n",
      "    return X_train, y_train, X_test, y_test   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performClassification(X_train, y_train, X_test, y_test, method, parameters, fout, savemodel):\n",
      "    \"\"\"\n",
      "    performs classification on daily returns using several algorithms (method).\n",
      "    method --> string algorithm\n",
      "    parameters --> list of parameters passed to the classifier (if any)\n",
      "    fout --> string with name of stock to be predicted\n",
      "    savemodel --> boolean. If TRUE saves the model to pickle file\n",
      "    \"\"\"\n",
      "   \n",
      "    if method == 'RF':   \n",
      "        return performRFClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
      "        \n",
      "    elif method == 'KNN':\n",
      "        return performKNNClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
      "    \n",
      "    elif method == 'SVM':   \n",
      "        return performSVMClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
      "    \n",
      "    elif method == 'ADA':\n",
      "        return performAdaBoostClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
      "    \n",
      "    elif method == 'GTB': \n",
      "        return performGTBClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
      "\n",
      "    elif method == 'QDA': \n",
      "        return performQDAClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performRFClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
      "    \"\"\"\n",
      "    Random Forest Binary Classification\n",
      "    \"\"\"\n",
      "    clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
      "    clf.fit(X_train, y_train)\n",
      "    \n",
      "    if savemodel == True:\n",
      "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
      "        with open(fname_out, 'wb') as f:\n",
      "            cPickle.dump(clf, f, -1)    \n",
      "    \n",
      "    accuracy = clf.score(X_test, y_test)\n",
      "    \n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performKNNClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
      "    \"\"\"\n",
      "    KNN binary Classification\n",
      "    \"\"\"\n",
      "    clf = neighbors.KNeighborsClassifier()\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    if savemodel == True:\n",
      "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
      "        with open(fname_out, 'wb') as f:\n",
      "            cPickle.dump(clf, f, -1)    \n",
      "    \n",
      "    accuracy = clf.score(X_test, y_test)\n",
      "    \n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performSVMClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
      "    \"\"\"\n",
      "    SVM binary Classification\n",
      "    \"\"\"\n",
      "    c = parameters[0]\n",
      "    g =  parameters[1]\n",
      "    clf = SVC()\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    if savemodel == True:\n",
      "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
      "        with open(fname_out, 'wb') as f:\n",
      "            cPickle.dump(clf, f, -1)    \n",
      "    \n",
      "    accuracy = clf.score(X_test, y_test)\n",
      "    \n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performAdaBoostClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
      "    \"\"\"\n",
      "    Ada Boosting binary Classification\n",
      "    \"\"\"\n",
      "    n = parameters[0]\n",
      "    l =  parameters[1]\n",
      "    clf = AdaBoostClassifier()\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    if savemodel == True:\n",
      "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
      "        with open(fname_out, 'wb') as f:\n",
      "            cPickle.dump(clf, f, -1)    \n",
      "    \n",
      "    accuracy = clf.score(X_test, y_test)\n",
      "    \n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performGTBClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
      "    \"\"\"\n",
      "    Gradient Tree Boosting binary Classification\n",
      "    \"\"\"\n",
      "    clf = GradientBoostingClassifier(n_estimators=100)\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    if savemodel == True:\n",
      "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
      "        with open(fname_out, 'wb') as f:\n",
      "            cPickle.dump(clf, f, -1)    \n",
      "    \n",
      "    accuracy = clf.score(X_test, y_test)\n",
      "    \n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performQDAClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
      "    \"\"\"\n",
      "    Quadratic Discriminant Analysis binary Classification\n",
      "    \"\"\"\n",
      "    def replaceTiny(x):\n",
      "        if (abs(x) < 0.0001):\n",
      "            x = 0.0001\n",
      "    \n",
      "    X_train = X_train.apply(replaceTiny)\n",
      "    X_test = X_test.apply(replaceTiny)\n",
      "    \n",
      "    clf = QDA()\n",
      "    clf.fit(X_train, y_train)\n",
      "\n",
      "    if savemodel == True:\n",
      "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
      "        with open(fname_out, 'wb') as f:\n",
      "            cPickle.dump(clf, f, -1)    \n",
      "    \n",
      "    accuracy = clf.score(X_test, y_test)\n",
      "    \n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Maximum time lag applied 9\n",
      "Delta days accounted:  9\n",
      "\n",
      "Size of data frame:  (5456, 153)\n",
      "Number of NaN after merging:  13311\n",
      "Number of NaN after time interpolation:  0\n",
      "Number of NaN after temporal shifting:  0\n",
      "Size of data frame after feature creation:  (5446, 225)\n",
      "\n",
      "Parameters -------------------------------->  [100]\n",
      "Size train set:  (5341, 224)\n",
      "Size of each fold:  534\n",
      "\n",
      "Splitting the first 2 chuncks at 1/2\n",
      "Size of train+test:  (1068, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (534, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 2:  0.514071294559\n",
      "\n",
      "Splitting the first 3 chuncks at 2/3\n",
      "Size of train+test:  (1602, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (1068, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 3:  0.538461538462\n",
      "\n",
      "Splitting the first 4 chuncks at 3/4\n",
      "Size of train+test:  (2136, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (1602, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 4:  0.480300187617\n",
      "\n",
      "Splitting the first 5 chuncks at 4/5\n",
      "Size of train+test:  (2670, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (2136, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 5:  0.527204502814\n",
      "\n",
      "Splitting the first 6 chuncks at 5/6\n",
      "Size of train+test:  (3204, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (2670, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 6:  0.547842401501\n",
      "\n",
      "Splitting the first 7 chuncks at 6/7\n",
      "Size of train+test:  (3738, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (3204, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 7:  0.544090056285\n",
      "\n",
      "Splitting the first 8 chuncks at 7/8\n",
      "Size of train+test:  (4272, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (3738, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 8:  0.55722326454\n",
      "\n",
      "Splitting the first 9 chuncks at 8/9\n",
      "Size of train+test:  (4806, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (4272, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 9:  0.547842401501\n",
      "\n",
      "Splitting the first 10 chuncks at 9/10\n",
      "Size of train+test:  (5340, 224)\n",
      "Performing RF Classification...\n",
      "Size of train set:  (4806, 224)\n",
      "Size of test set:  (533, 224)\n",
      "Accuracy on fold 10:  0.519699812383\n",
      "\n",
      "Mean Accuracy for (9, 9): 0.530748'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "'\\nMaximum time lag applied 9\\nDelta days accounted:  9\\n\\nSize of data frame:  (5456, 153)\\nNumber of NaN after merging:  13311\\nNumber of NaN after time interpolation:  0\\nNumber of NaN after temporal shifting:  0\\nSize of data frame after feature creation:  (5446, 225)\\n\\nParameters -------------------------------->  [100]\\nSize train set:  (5341, 224)\\nSize of each fold:  534\\n\\nSplitting the first 2 chuncks at 1/2\\nSize of train+test:  (1068, 224)\\nPerforming RF Classification...\\nSize of train set:  (534, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 2:  0.514071294559\\n\\nSplitting the first 3 chuncks at 2/3\\nSize of train+test:  (1602, 224)\\nPerforming RF Classification...\\nSize of train set:  (1068, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 3:  0.538461538462\\n\\nSplitting the first 4 chuncks at 3/4\\nSize of train+test:  (2136, 224)\\nPerforming RF Classification...\\nSize of train set:  (1602, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 4:  0.480300187617\\n\\nSplitting the first 5 chuncks at 4/5\\nSize of train+test:  (2670, 224)\\nPerforming RF Classification...\\nSize of train set:  (2136, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 5:  0.527204502814\\n\\nSplitting the first 6 chuncks at 5/6\\nSize of train+test:  (3204, 224)\\nPerforming RF Classification...\\nSize of train set:  (2670, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 6:  0.547842401501\\n\\nSplitting the first 7 chuncks at 6/7\\nSize of train+test:  (3738, 224)\\nPerforming RF Classification...\\nSize of train set:  (3204, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 7:  0.544090056285\\n\\nSplitting the first 8 chuncks at 7/8\\nSize of train+test:  (4272, 224)\\nPerforming RF Classification...\\nSize of train set:  (3738, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 8:  0.55722326454\\n\\nSplitting the first 9 chuncks at 8/9\\nSize of train+test:  (4806, 224)\\nPerforming RF Classification...\\nSize of train set:  (4272, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 9:  0.547842401501\\n\\nSplitting the first 10 chuncks at 9/10\\nSize of train+test:  (5340, 224)\\nPerforming RF Classification...\\nSize of train set:  (4806, 224)\\nSize of test set:  (533, 224)\\nAccuracy on fold 10:  0.519699812383\\n\\nMean Accuracy for (9, 9): 0.530748'"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def performFeatureSelection(maxdeltas, maxlags, fout, cut, start_test, path_datasets, savemodel, method, folds, parameters):\n",
      "    \"\"\"\n",
      "    Performs Feature selection for a specific algorithm\n",
      "    \"\"\"\n",
      "    \n",
      "    for maxlag in range(3, maxlags + 2):\n",
      "        lags = range(2, maxlag) \n",
      "        print ''\n",
      "        print '============================================================='\n",
      "        print 'Maximum time lag applied', max(lags)\n",
      "        print ''\n",
      "        for maxdelta in range(3, maxdeltas + 2):\n",
      "            datasets = loadDatasets(path_datasets, fout)\n",
      "            delta = range(2, maxdelta) \n",
      "            print 'Delta days accounted: ', max(delta)\n",
      "            datasets = applyRollMeanDelayedReturns(datasets, delta)\n",
      "            finance = mergeDataframes(datasets, 6, cut)\n",
      "            print 'Size of data frame: ', finance.shape\n",
      "            print 'Number of NaN after merging: ', count_missing(finance)\n",
      "            finance = finance.interpolate(method='linear')\n",
      "            print 'Number of NaN after time interpolation: ', count_missing(finance)\n",
      "            finance = finance.fillna(finance.mean())\n",
      "            print 'Number of NaN after mean interpolation: ', count_missing(finance)    \n",
      "            finance = applyTimeLag(finance, lags, delta)\n",
      "            print 'Number of NaN after temporal shifting: ', count_missing(finance)\n",
      "            print 'Size of data frame after feature creation: ', finance.shape\n",
      "            X_train, y_train, X_test, y_test  = prepareDataForClassification(finance, start_test)\n",
      "            \n",
      "            print performCV(X_train, y_train, folds, method, parameters, fout, savemodel)\n",
      "            print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Maximum time lag applied 9\n",
      "Delta days accounted:  9\n",
      "Size of data frame:  (5456, 153)\n",
      "Number of NaN after merging:  13311\n",
      "Number of NaN after time interpolation:  0\n",
      "Number of NaN after temporal shifting:  0\n",
      "Size of data frame after feature creation:  (5446, 225)\n",
      "Accuracy on Test Set: 0.571428571429\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "'\\nMaximum time lag applied 9\\nDelta days accounted:  9\\nSize of data frame:  (5456, 153)\\nNumber of NaN after merging:  13311\\nNumber of NaN after time interpolation:  0\\nNumber of NaN after temporal shifting:  0\\nSize of data frame after feature creation:  (5446, 225)\\nAccuracy on Test Set: 0.571428571429\\n'"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# last trading day accounted\n",
      "end_period = datetime.datetime(2014,8,28)\n",
      "\n",
      "cut = datetime.datetime(1993,1,1)\n",
      "start_test = cut\n",
      "# symbol of the stock required for future plotting\n",
      "symbol = 'S&P-500'\n",
      "path_datasets ='C:/Forcast'\n",
      "\n",
      "# name of the file of the output of prediction (S&P 500 in this case)\n",
      "name = path_datasets + '/sp500.csv'\n",
      "\n",
      "# calls the best model previously saved in pickle file and runs it on the test set retutning an array of 0,1 (Down, Up) according to predicted returns\n",
      "prediction =getPredictionFromBestModel(9, 9, 'sp500', cut, start_test, path_datasets, 'sp500_57.pickle')[0]\n",
      "\n",
      "# dataframe of S&P 500 historical prices (saved locally from Yahho Finance)\n",
      "bars = pd.read_csv(name, index_col=0, parse_dates=True)    \n",
      "\n",
      "# subset of the data corresponding to test set\n",
      "bars = bars[start_test:end_period]\n",
      "\n",
      "# initialize empty dataframe indexed as the bars. There's going to be perfect match between dates in bars and signals \n",
      "signals = pd.DataFrame(index=bars.index)\n",
      "\n",
      "# initialize signals.signal column to zero\n",
      "signals['signal'] = 0.0\n",
      "\n",
      "# copying into signals.signal column results of prediction\n",
      "signals['signal'] = prediction\n",
      "\n",
      "# replace the zeros with -1 (new encoding for Down day)\n",
      "signals.signal[signals.signal == 0] = -1\n",
      "\n",
      "# compute the difference between consecutive entries in signals.signal. As\n",
      "# signals.signal was an array of 1 and -1 return signals.positions will \n",
      "# be an array of 0s and 2s.\n",
      "signals['positions'] = signals['signal'].diff()     \n",
      "\n",
      "# calling portfolio evaluation on signals (predicted returns) and bars \n",
      "# (actual returns)\n",
      "portfolio = pystocks.MarketIntradayPortfolio(symbol, bars, signals)\n",
      "\n",
      "# backtesting the portfolio and generating returns on top of that \n",
      "returns = portfolio.backtest_portfolio()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'loadDatasets' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-63-a21fe1df337e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# calls the best model previously saved in pickle file and runs it on the test set retutning an array of 0,1 (Down, Up) according to predicted returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mgetPredictionFromBestModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sp500'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sp500_57.pickle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# dataframe of S&P 500 historical prices (saved locally from Yahho Finance)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-55-cb98fe1b6ebc>\u001b[0m in \u001b[0;36mgetPredictionFromBestModel\u001b[1;34m(bestdelta, bestlags, fout, cut, start_test, path_datasets, best_model)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m      5\u001b[0m     \u001b[0mlags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestlags\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadDatasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestdelta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapplyRollMeanDelayedReturns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'loadDatasets' is not defined"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getPredictionFromBestModel(bestdelta, bestlags, fout, cut, start_test, path_datasets, best_model):\n",
      "    \"\"\"\n",
      "    returns array of prediction and score from best model.\n",
      "    \"\"\"\n",
      "    lags = range(2, bestlags + 1) \n",
      "    datasets = loadDatasets(path_datasets, fout)\n",
      "    delta = range(2, bestdelta + 1) \n",
      "    datasets = applyRollMeanDelayedReturns(datasets, delta)\n",
      "    finance = mergeDataframes(datasets, 6, cut)\n",
      "    finance = finance.interpolate(method='linear')\n",
      "    finance = finance.fillna(finance.mean())    \n",
      "    finance = applyTimeLag(finance, lags, delta)\n",
      "    X_train, y_train, X_test, y_test  = prepareDataForClassification(finance, start_test)    \n",
      "    with open(best_model, 'rb') as fin:\n",
      "        model = cPickle.load(fin)        \n",
      "        \n",
      "    return model.predict(X_test), model.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MarketIntradayPortfolio(Portfolio):\n",
      "    \"\"\"Buys or sells 500 shares of an asset at the opening price of\n",
      "    every bar, depending upon the direction of the forecast, closing \n",
      "    out the trade at the close of the bar.\n",
      "\n",
      "    Requires:\n",
      "    symbol - A stock symbol which forms the basis of the portfolio.\n",
      "    bars - A DataFrame of bars for a symbol set.\n",
      "    signals - A pandas DataFrame of signals (1, -1) for each symbol.\n",
      "    initial_capital - The amount in cash at the start of the portfolio.\"\"\"\n",
      "\n",
      "    def __init__(self, symbol, bars, signals, initial_capital=100000.0, shares=500):\n",
      "        self.symbol = symbol        \n",
      "        self.bars = bars\n",
      "        self.signals = signals\n",
      "        self.initial_capital = float(initial_capital)\n",
      "        self.shares = int(shares)\n",
      "        self.positions = self.generate_positions()\n",
      "        \n",
      "    def generate_positions(self):\n",
      "        \"\"\"Generate the positions DataFrame, based on the signals\n",
      "        provided by the 'signals' DataFrame.\"\"\"\n",
      "        positions = pd.DataFrame(index=self.signals.index).fillna(0.0)\n",
      "\n",
      "        positions[self.symbol] = self.shares*self.signals['signal']\n",
      "        return positions\n",
      "                    \n",
      "    def backtest_portfolio(self):\n",
      "        \"\"\"Backtest the portfolio and return a DataFrame containing\n",
      "        the equity curve and the percentage returns.\"\"\"\n",
      "       \n",
      "        portfolio = pd.DataFrame(index=self.positions.index)\n",
      "        pos_diff = self.positions.diff()\n",
      "            \n",
      "        portfolio['price_diff'] = self.bars['Close_Out']-self.bars['Open_Out']\n",
      "        portfolio['price_diff'][0:5] = 0.0\n",
      "        portfolio['profit'] = self.positions[self.symbol] * portfolio['price_diff']\n",
      "     \n",
      "        portfolio['total'] = self.initial_capital + portfolio['profit'].cumsum()\n",
      "        portfolio['returns'] = portfolio['total'].pct_change()\n",
      "        return portfolio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from abc import ABCMeta, abstractmethod\n",
      "\n",
      "class Portfolio(object):\n",
      "    \"\"\"An abstract base class representing a portfolio of \n",
      "    positions (including both instruments and cash), determined\n",
      "    on the basis of a set of signals provided by a Strategy.\"\"\"\n",
      "\n",
      "    __metaclass__ = ABCMeta\n",
      "\n",
      "    @abstractmethod\n",
      "    def generate_positions(self):\n",
      "        \"\"\"Provides the logic to determine how the portfolio \n",
      "        positions are allocated on the basis of forecasting\n",
      "        signals and available cash.\"\"\"\n",
      "        raise NotImplementedError(\"Should implement generate_positions()!\")\n",
      "\n",
      "    @abstractmethod\n",
      "    def backtest_portfolio(self):\n",
      "        \"\"\"Provides the logic to generate the trading orders\n",
      "        and subsequent equity curve (i.e. growth of total equity),\n",
      "        as a sum of holdings and cash, and the bar-period returns\n",
      "        associated with this curve based on the 'positions' DataFrame.\n",
      "\n",
      "        Produces a portfolio object that can be examined by \n",
      "        other classes/functions.\"\"\"\n",
      "        raise NotImplementedError(\"Should implement backtest_portfolio()!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "   # Plot results\n",
      "    f, ax = plt.subplots(2, sharex=True)\n",
      "    f.patch.set_facecolor('white')\n",
      "    ylabel = symbol + ' Close Price in $'\n",
      "    bars['Close_Out'].plot(ax=ax[0], color='r', lw=3.)    \n",
      "    ax[0].set_ylabel(ylabel, fontsize=18)\n",
      "    ax[0].set_xlabel('', fontsize=18)\n",
      "    ax[0].legend(('Close Price S&P-500',), loc='upper left', prop={\"size\":18})\n",
      "    ax[0].set_title('S&P 500 Close Price VS Portofolio Performance (1 April 2014 - 28 August 2014)', fontsize=20, fontweight=\"bold\")\n",
      "    \n",
      "    returns['total'].plot(ax=ax[1], color='b', lw=3.)  \n",
      "    ax[1].set_ylabel('Portfolio value in $', fontsize=18)\n",
      "    ax[1].set_xlabel('Date', fontsize=18)\n",
      "    ax[1].legend(('Portofolio Performance. Capital Invested: 100k $. Shares Traded per day: 500+500',), loc='upper left', prop={\"size\":18})            \n",
      "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
      "    loc = ax[1].xaxis.get_major_locator()\n",
      "    loc.maxticks[DAILY] = 24\n",
      "\n",
      "    figManager = plt.get_current_fig_manager()\n",
      "    figManager.window.showMaximized()\n",
      "    \n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}